# # ğŸ“¡ TelecomX â€“ Churn Prediction Challenge

Bienvenido a **TelecomX Churn Prediction**, un proyecto de Ciencia de Datos enfocado en la identificaciÃ³n y predicciÃ³n de clientes con alta probabilidad de abandono (Churn).

Este proyecto forma parte de un challenge prÃ¡ctico de Alura One donde se desarrolla un flujo completo de Machine Learning: desde el anÃ¡lisis exploratorio hasta la evaluaciÃ³n comparativa de mÃºltiples modelos de clasificaciÃ³n.

---

## ğŸ¯ Objetivo del Proyecto

El objetivo principal es **predecir quÃ© clientes tienen mayor probabilidad de cancelar el servicio**, utilizando variables demogrÃ¡ficas, contractuales y de comportamiento.

La meta no es solo entrenar modelos, sino:

- ğŸ“Š Comprender los factores que influyen en el churn
- ğŸ§  Comparar distintos algoritmos de clasificaciÃ³n
- ğŸ“ˆ Evaluar mÃ©tricas relevantes para negocio
- ğŸ” Identificar el modelo con mejor desempeÃ±o

---

## ğŸ§© MetodologÃ­a Aplicada

El proyecto sigue un flujo estructurado de anÃ¡lisis:

### 1ï¸âƒ£ AnÃ¡lisis Exploratorio de Datos (EDA)
- DistribuciÃ³n de la variable objetivo
- Correlaciones entre variables numÃ©ricas
- IdentificaciÃ³n de variables relevantes
- AnÃ¡lisis de patrones asociados al churn

### 2ï¸âƒ£ Preprocesamiento
- SeparaciÃ³n de variables numÃ©ricas y categÃ³ricas
- CodificaciÃ³n con One-Hot Encoding
- Escalado de variables numÃ©ricas
- Uso de `ColumnTransformer`
- ImplementaciÃ³n de `Pipeline` para evitar data leakage

### 3ï¸âƒ£ Modelado
Se entrenaron y compararon mÃºltiples modelos de clasificaciÃ³n:

- Logistic Regression
- Decision Tree
- Decision Tree (Balanced)
- Random Forest
- Gradient Boosting

### 4ï¸âƒ£ EvaluaciÃ³n
Se utilizaron mÃ©tricas clave para problemas de churn:

- Accuracy
- Recall (Churn)
- F1-score
- ROC-AUC

---

## ğŸ“Š Resultados Destacados

Entre los modelos evaluados:

- ğŸ“ˆ **Gradient Boosting** mostrÃ³ la mejor capacidad discriminativa (mayor ROC-AUC).
- âš– **Logistic Regression** presentÃ³ el mejor equilibrio general entre Recall y F1-score.
- ğŸŒ² Los Ã¡rboles individuales mostraron menor capacidad de generalizaciÃ³n.
- ğŸŒ³ Los modelos ensamblados superaron claramente a los modelos simples.

Esto demuestra la importancia de comparar arquitecturas antes de elegir un modelo final.

---

## ğŸ’¡ Principales Insights

- El problema presenta seÃ±ales de desbalance en la clase churn.
- La optimizaciÃ³n de hiperparÃ¡metros puede mejorar significativamente el rendimiento.
- Ajustar el umbral de clasificaciÃ³n podrÃ­a incrementar la detecciÃ³n de clientes en riesgo.
- Modelos mÃ¡s complejos no siempre superan ampliamente a modelos lineales bien ajustados.

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- ğŸ Python
- pandas
- numpy
- matplotlib / seaborn
- scikit-learn
- Jupyter Notebook

---

## ğŸ“ Estructura del Proyecto
